{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code adapted from https://towardsdatascience.com/understanding-and-coding-a-resnet-in-keras-446d7ff84d33#:~:text=The%20Keras%20ResNet%20got%20to,to%20do%20with%20weight%20initializations.\n",
    "# import plaidml\n",
    "# import plaidml.keras\n",
    "# plaidml.install_backend()\n",
    "# import os\n",
    "# os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n",
    "    \n",
    "import random\n",
    "random.seed(10)\n",
    "\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "\n",
    "# Clean Script\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.utils import load_img\n",
    "\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D,GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Sequential,Model,load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "path_to_directory = 'imagedata/'\n",
    "\n",
    "\n",
    "# Collect paths to images based on label\n",
    "patientPaths= glob(os.path.join(path_to_directory, \"*\", \"\"))\n",
    "\n",
    "# print(patientPaths)\n",
    "nonCancerTrPaths = []\n",
    "nonCancerTestPaths = []\n",
    "cancerousTrPaths = []\n",
    "cancerousTestPaths = [] \n",
    "\n",
    "for i in range(0,224):\n",
    "    nonCancerTrPaths.extend(glob(os.path.join(patientPaths[i], \"0/\", \"*\")))\n",
    "    cancerousTrPaths.extend(glob(os.path.join(patientPaths[i], \"1/\", \"*\")))\n",
    "\n",
    "\n",
    "for i in range(224,279):\n",
    "    nonCancerTestPaths.extend(glob(os.path.join(patientPaths[i], \"0/\", \"*\")))\n",
    "    cancerousTestPaths.extend(glob(os.path.join(patientPaths[i], \"1/\", \"*\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn filepaths into image arrays to train a model\n",
    "def paths_to_image(paths, label, num_samples):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for path in paths[0:num_samples]:\n",
    "        image = load_img(path)\n",
    "        image = image.resize([50, 50])\n",
    "        imgArray = tf.keras.utils.img_to_array(image)\n",
    "        images.append(imgArray)\n",
    "        labels.append(label)\n",
    "    return [images[0: num_samples], labels[0: num_samples]]\n",
    "\n",
    "nonCancerTrImages = paths_to_image(nonCancerTrPaths, 0, len(nonCancerTrPaths))\n",
    "cancerTrImages = paths_to_image(cancerousTrPaths, 1, len(cancerousTrPaths))\n",
    "\n",
    "nonCancerTestImages = paths_to_image(nonCancerTestPaths, 0, len(nonCancerTestPaths))\n",
    "cancerTestImages = paths_to_image(cancerousTestPaths, 1, len(cancerousTestPaths))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = nonCancerTrImages[0] + cancerTrImages[0]\n",
    "y_train = nonCancerTrImages[1] + cancerTrImages[1]\n",
    "\n",
    "x_test = nonCancerTestImages[0]+ cancerTestImages[0]\n",
    "y_test = nonCancerTestImages[1]+ cancerTestImages[1]\n",
    "\n",
    "# # split images into train, val, test\n",
    "# allImages = nonCancerImages[0] + cancerImages[0]\n",
    "# allLabels = nonCancerImages[1] + cancerImages[1]\n",
    "\n",
    "# x_train, x_toSplit, y_train, y_toSplit = train_test_split(allImages, allLabels, test_size=.5, stratify= allLabels, random_state = 10)\n",
    "# x_val, x_test, y_val, y_test = train_test_split(x_toSplit, y_toSplit, test_size=.5, stratify=y_toSplit, random_state = 10)\n",
    "\n",
    "\n",
    "#function which rotates image a certain number of degrees = to rotation\n",
    "def rotate_image(X, y, rotation, num_to_rotate = None):\n",
    "    rotatedImages = []\n",
    "    labels = []\n",
    "    cancerX = X[y==1]\n",
    "    if num_to_rotate is not None and num_to_rotate < len(cancerX):\n",
    "        cancerX = cancerX[0: num_to_rotate]\n",
    "    for img in cancerX:\n",
    "        image = tf.keras.utils.array_to_img(img)\n",
    "        image = image.resize([50, 50])\n",
    "        rotateimg = image.rotate(rotation)\n",
    "        imgArray = tf.keras.utils.img_to_array(rotateimg)\n",
    "        rotatedImages.append(imgArray)\n",
    "        labels.append(1)\n",
    "    return [rotatedImages, labels]\n",
    "\n",
    "\n",
    "train90 = rotate_image(np.array(cancerTrImages[0]), np.array(cancerTrImages[1]), 90)\n",
    "train180 = rotate_image(np.array(cancerTrImages[0]), np.array(cancerTrImages[1]), 180)\n",
    "train270 = rotate_image(np.array(cancerTrImages[0]), np.array(cancerTrImages[1]), 270, 42132)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of cancer images in training set\", str((len(train180[0]) + len(train90[0])) + sum(y_train)))\n",
    "print(\"Number of benign images in training set\", str(len(y_train) - sum(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(x_train)\n",
    "train90[0] = np.array(train90[0])\n",
    "train180[0] = np.array(train180[0])\n",
    "y_train = np.array(y_train)\n",
    "train90[1] = np.array(train90[1])\n",
    "train180[1] = np.array(train180[1])\n",
    "\n",
    "training_x = np.concatenate((x_train, train90[0], train180[0],train270[0]), axis=0)\n",
    "training_y = np.concatenate((y_train, train90[1], train180[1],train270[1]))\n",
    "\n",
    "\n",
    "# Shuffle order\n",
    "zipper = list(zip(training_x, training_y))\n",
    "random.shuffle(zipper)\n",
    "training_x, training_y = zip(*zipper)\n",
    "\n",
    "datagen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)\n",
    "datagen.fit(training_x)\n",
    "\n",
    "# Because of computing power problems we subset to the first 20000 images in training\n",
    "training_x = training_x[0:20000]\n",
    "training_y = training_y[0:20000]\n",
    "\n",
    "train_iterator = datagen.flow(np.array(training_x), np.array(training_y))\n",
    "val_iterator = datagen.flow(np.array(x_val), np.array(y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# #Learning rates above .01 are not useful\n",
    "import keras.backend as K\n",
    "\n",
    "# learning_rates = [.0001, .0005, .001, .005, .01, .05, .1]\n",
    "\n",
    "# for lr in learning_rates:\n",
    "#     model = VGG16(weights=None, include_top=True, input_shape= (50, 50,3), classes=2, classifier_activation='softmax')\n",
    "#     adam = Adam(learning_rate=lr)\n",
    "#     model.compile(optimizer= adam, loss=tf.keras.losses.sparse_categorical_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "#     print(\"FITTING\")\n",
    "#     history = model.fit(np.array(x_train), np.array(y_train), epochs=10, validation_data=(np.array(x_test), np.array(y_test)))\n",
    "#     plt.plot(history.history['accuracy'], label='accuracy')\n",
    "#     plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "#     plt.xlabel('Epoch')\n",
    "#     plt.ylabel('Accuracy')\n",
    "#     plt.ylim([0.5, 1])\n",
    "#     plt.legend(loc='lower right')\n",
    "#     plt.title(\"Learning Rate: \" + str(lr))\n",
    "#     plt.show()\n",
    "\n",
    "# The model outputs a value between 0 and 1, which can be thought of as a probability of being a cancer or not\n",
    "# model.predict to find the pseudo probability which is a measure of confidence\n",
    "# we can output the score and the prediction\n",
    "# activation map to find the feature\n",
    "\n",
    "\n",
    "# LR = .0001 achieves the highest validation accuracy\n",
    "# Increase number of epochs to see if more epochs further increases val error\n",
    "LR = .0001\n",
    "model = VGG16(weights=None, include_top=True, input_shape= (50, 50,3), classes=2, classifier_activation='softmax')\n",
    "adam = Adam(learning_rate=LR)\n",
    "model.compile(optimizer= adam, loss=tf.keras.losses.sparse_categorical_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "print(\"FITTING\")\n",
    "history = model.fit(train_iterator, epochs=15, validation_data=val_iterator)\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.5, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.title(\"Learning Rate: \" + str(LR))\n",
    "plt.show()\n",
    "\n",
    "model.save(\"April1AB20k2023\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LR = .0001 achieves the highest validation accuracy\n",
    "# Increase number of epochs to see if more epochs further increases val error\n",
    "# model = VGG16(weights=None, include_top=True, input_shape= (50, 50,3), classes=2, classifier_activation='softmax')\n",
    "# adam = Adam(learning_rate=.0001)\n",
    "# model.compile(optimizer= adam, loss=tf.keras.losses.sparse_categorical_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "# print(\"FITTING\")\n",
    "# history = model.fit(np.array(x_train), np.array(y_train), epochs=15, validation_data=(np.array(x_test), np.array(y_test)))\n",
    "# plt.plot(history.history['accuracy'], label='accuracy')\n",
    "# plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.ylim([0.5, 1])\n",
    "# plt.legend(loc='lower right')\n",
    "# plt.title(\"Learning Rate: \" + str(lr))\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "OpError",
     "evalue": "April1AB20k2023/variables/variables.data-00000-of-00001; No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOpError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mApril1AB20k2023\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cancerImages/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cancerImages/lib/python3.10/site-packages/tensorflow/python/training/py_checkpoint_reader.py:45\u001b[0m, in \u001b[0;36merror_translator\u001b[0;34m(e)\u001b[0m\n\u001b[1;32m     43\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m errors_impl\u001b[38;5;241m.\u001b[39mInternalError(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, error_message)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 45\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m errors_impl\u001b[38;5;241m.\u001b[39mOpError(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, error_message, errors_impl\u001b[38;5;241m.\u001b[39mUNKNOWN)\n",
      "\u001b[0;31mOpError\u001b[0m: April1AB20k2023/variables/variables.data-00000-of-00001; No such file or directory"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "model = tf.keras.models.load_model('April1AB20k2023')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 50, 50, 3)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 50, 50, 64)        1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 50, 50, 64)        36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 25, 25, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 25, 25, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 25, 25, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 12, 12, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 12, 12, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 12, 12, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 12, 12, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 6, 6, 256)         0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 6, 6, 512)         1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 3, 3, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 3, 3, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 3, 3, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 3, 3, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 512)               0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              2101248   \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 2)                 8194      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,605,442\n",
      "Trainable params: 33,605,442\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datagen' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test_iterator \u001b[38;5;241m=\u001b[39m \u001b[43mdatagen\u001b[49m\u001b[38;5;241m.\u001b[39mflow(np\u001b[38;5;241m.\u001b[39marray(x_test), np\u001b[38;5;241m.\u001b[39marray(y_test))\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mevaluate(test_iterator)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'datagen' is not defined"
     ]
    }
   ],
   "source": [
    "test_iterator = datagen.flow(np.array(x_test), np.array(y_test))\n",
    "\n",
    "model.evaluate(test_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array(y_test)\n",
    "a[a==1].shape\n",
    " \n",
    "\n",
    "acc = (49684*0.4283320903778076+0.8424640893936157*19697) /(49684+19697)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prediction = model.predict(np.array(x_test))\n",
    "# ypred2 = model.predict_classes(np.array(x_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = np.zeros(y_prediction.shape[0])\n",
    "mask = (y_prediction[:,0]<0.5)\n",
    "prediction[mask] = 1\n",
    "print(prediction)\n",
    "\n",
    "equal = np.zeros(y_prediction.shape[0])\n",
    "equal[prediction == np.array(y_test)] = 1\n",
    "\n",
    "accuracy = np.sum(equal)/y_prediction.shape[0]\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[np.array(y_test) == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "result = confusion_matrix(y_test, prediction , normalize='pred')\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=result )\n",
    "\n",
    "disp.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = np.zeros(y_prediction.shape[0])\n",
    "mask = (y_prediction[:,1]<0.8)\n",
    "prediction[mask] = 1\n",
    "print(prediction)\n",
    "\n",
    "equal = np.zeros(y_prediction.shape[0])\n",
    "equal[prediction == np.array(y_test)] = 1\n",
    "\n",
    "accuracy = np.sum(equal)/y_prediction.shape[0]\n",
    "accuracy\n",
    "\n",
    "result = confusion_matrix(y_test, prediction , normalize='pred')\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=result )\n",
    "\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cancer evaluation\n",
    "cancer_iterator = datagen.flow(np.array(np.array(x_test)[np.array(y_test) == 1]), np.array(y_test)[np.array(y_test) == 1])\n",
    "\n",
    "model.evaluate(cancer_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# benign evaluation\n",
    "\n",
    "benign_iterator = datagen.flow(np.array(np.array(x_test)[np.array(y_test) == 0]), np.array(y_test)[np.array(y_test) == 0])\n",
    "\n",
    "model.evaluate(benign_iterator)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "## the penalty of missing a cancer is 2 million dollars * .05 100000\n",
    "## the penalty of diagnosing a cancer when it isn't there is lets say 20000\n",
    "import keras\n",
    "def get_img_array(img_path, size):\n",
    "    # `img` is a PIL image of size 299x299\n",
    "    img = load_img(img_path, target_size=size)\n",
    "    # `array` is a float32 Numpy array of shape (299, 299, 3)\n",
    "    array = tf.keras.utils.img_to_array(img)\n",
    "    # We add a dimension to transform our array into a \"batch\"\n",
    "    # of size (1, 299, 299, 3)\n",
    "    array = np.expand_dims(array, axis=0)\n",
    "    return array\n",
    "\n",
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "    # First, we create a model that maps the input image to the activations\n",
    "    # of the last conv layer as well as the output predictions\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    # Then, we compute the gradient of the top predicted class for our input image\n",
    "    # with respect to the activations of the last conv layer\n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output, preds = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(preds[0])\n",
    "        class_channel = preds[:, pred_index]\n",
    "\n",
    "    # This is the gradient of the output neuron (top predicted or chosen)\n",
    "    # with regard to the output feature map of the last conv layer\n",
    "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
    "\n",
    "    # This is a vector where each entry is the mean intensity of the gradient\n",
    "    # over a specific feature map channel\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    # We multiply each channel in the feature map array\n",
    "    # by \"how important this channel is\" with regard to the top predicted class\n",
    "    # then sum all the channels to obtain the heatmap class activation\n",
    "    last_conv_layer_output = last_conv_layer_output[0]\n",
    "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "\n",
    "    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    return heatmap.numpy()\n",
    "\n",
    "img_size = (50, 50)\n",
    "path = \"imagedata/10253/0/10253_idx5_x1001_y1001_class0.png\"\n",
    "heatmap = make_gradcam_heatmap(datagen.flow(get_img_array(path, img_size))[0], model, \"block5_conv3\")\n",
    "plt.matshow(heatmap)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "def save_and_display_gradcam(img_path, heatmap, cam_path=\"cam.jpg\", alpha=0.4):\n",
    "    # Load the original image\n",
    "    img = load_img(img_path)\n",
    "    img = tf.keras.utils.img_to_array(img)\n",
    "\n",
    "    # Rescale heatmap to a range 0-255\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "\n",
    "    # Use jet colormap to colorize heatmap\n",
    "    jet = cm.get_cmap(\"jet\")\n",
    "\n",
    "    # Use RGB values of the colormap\n",
    "    jet_colors = jet(np.arange(256))[:, :3]\n",
    "    jet_heatmap = jet_colors[heatmap]\n",
    "\n",
    "    # Create an image with RGB colorized heatmap\n",
    "    jet_heatmap = tf.keras.utils.array_to_img(jet_heatmap)\n",
    "    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
    "    jet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)\n",
    "\n",
    "    # Superimpose the heatmap on original image\n",
    "    superimposed_img = jet_heatmap * alpha + img\n",
    "    superimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)\n",
    "\n",
    "    # Save the superimposed image\n",
    "    superimposed_img.save(cam_path)\n",
    "\n",
    "    # Display Grad CAM\n",
    "    display(Image(cam_path))\n",
    "\n",
    "\n",
    "save_and_display_gradcam(path, heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
