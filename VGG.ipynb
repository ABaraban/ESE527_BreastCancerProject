{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-19 15:28:10.558619: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# code adapted from https://towardsdatascience.com/understanding-and-coding-a-resnet-in-keras-446d7ff84d33#:~:text=The%20Keras%20ResNet%20got%20to,to%20do%20with%20weight%20initializations.\n",
    "# import plaidml\n",
    "# import plaidml.keras\n",
    "# plaidml.install_backend()\n",
    "# import os\n",
    "# os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n",
    "NUM_SAMP = 1000\n",
    "import random\n",
    "random.seed(10)\n",
    "\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "\n",
    "# Clean Script\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.utils import load_img\n",
    "\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D,GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Sequential,Model,load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Collect paths to images based on label\n",
    "nonCancerPaths = glob('imagedata/*/0/*.png')\n",
    "cancerousPaths = glob('imagedata/*/1/*.png')\n",
    "\n",
    "# Turn filepaths into image arrays to train a model\n",
    "def paths_to_image(paths, label, num_samples):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for path in paths[0:num_samples]:\n",
    "        image = load_img(path)\n",
    "        image = image.resize([50, 50])\n",
    "        imgArray = tf.keras.utils.img_to_array(image)\n",
    "        images.append(imgArray)\n",
    "        labels.append(label)\n",
    "    return [images[0: num_samples], labels[0: num_samples]]\n",
    "nonCancerImages = paths_to_image(nonCancerPaths, 0, len(nonCancerPaths))\n",
    "cancerImages = paths_to_image(cancerousPaths, 1, len(cancerousPaths))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split images into train, val, test\n",
    "allImages = nonCancerImages[0] + cancerImages[0]\n",
    "allLabels = nonCancerImages[1] + cancerImages[1]\n",
    "\n",
    "x_train, x_toSplit, y_train, y_toSplit = train_test_split(allImages, allLabels, test_size=.5, stratify= allLabels, random_state = 10)\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_toSplit, y_toSplit, test_size=.5, stratify=y_toSplit, random_state = 10)\n",
    "\n",
    "\n",
    "#function which rotates image a certain number of degrees = to rotation\n",
    "def rotate_image(X, y, rotation, num_to_rotate = None):\n",
    "    rotatedImages = []\n",
    "    labels = []\n",
    "    cancerX = X[y==1]\n",
    "    if num_to_rotate is not None and num_to_rotate < len(cancerX):\n",
    "        cancerX = cancerX[0: num_to_rotate]\n",
    "    for img in cancerX:\n",
    "        image = tf.keras.utils.array_to_img(img)\n",
    "        image = image.resize([50, 50])\n",
    "        rotateimg = image.rotate(rotation)\n",
    "        imgArray = tf.keras.utils.img_to_array(rotateimg)\n",
    "        rotatedImages.append(imgArray)\n",
    "        labels.append(1)\n",
    "    return [rotatedImages, labels]\n",
    "\n",
    "\n",
    "train90 = rotate_image(np.array(x_train), np.array(y_train), 90)\n",
    "train180 = rotate_image(np.array(x_train), np.array(y_train), 180, 20583)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cancer images in training set 99369\n",
      "Number of benign images in training set 99369\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of cancer images in training set\", str((len(train180[0]) + len(train90[0])) + sum(y_train)))\n",
    "print(\"Number of benign images in training set\", str(len(y_train) - sum(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(x_train)\n",
    "train90[0] = np.array(train90[0])\n",
    "train180[0] = np.array(train180[0])\n",
    "y_train = np.array(y_train)\n",
    "train90[1] = np.array(train90[1])\n",
    "train180[1] = np.array(train180[1])\n",
    "\n",
    "training_x = np.concatenate((x_train, train90[0], train180[0]), axis=0)\n",
    "training_y = np.concatenate((y_train, train90[1], train180[1]))\n",
    "\n",
    "\n",
    "# Shuffle order\n",
    "zipper = list(zip(training_x, training_y))\n",
    "random.shuffle(zipper)\n",
    "training_x, training_y = zip(*zipper)\n",
    "\n",
    "datagen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)\n",
    "datagen.fit(training_x)\n",
    "\n",
    "# Because of computing power problems we subset to the first 10000 images in training\n",
    "training_x = training_x[0:10000]\n",
    "training_y = training_y[0:10000]\n",
    "\n",
    "train_iterator = datagen.flow(np.array(training_x), np.array(training_y))\n",
    "val_iterator = datagen.flow(np.array(x_val), np.array(y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-19 15:35:49.736084: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FITTING\n",
      "Epoch 1/15\n",
      "313/313 [==============================] - 587s 2s/step - loss: 0.6879 - accuracy: 0.5423 - val_loss: 0.7133 - val_accuracy: 0.3774\n",
      "Epoch 2/15\n",
      "313/313 [==============================] - 573s 2s/step - loss: 0.5206 - accuracy: 0.7711 - val_loss: 0.4840 - val_accuracy: 0.7745\n",
      "Epoch 3/15\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.4382 - accuracy: 0.8049"
     ]
    }
   ],
   "source": [
    "# #Learning rates above .01 are not useful\n",
    "\n",
    "# learning_rates = [.0001, .0005, .001, .005, .01, .05, .1]\n",
    "\n",
    "# for lr in learning_rates:\n",
    "#     model = VGG16(weights=None, include_top=True, input_shape= (50, 50,3), classes=2, classifier_activation='softmax')\n",
    "#     adam = Adam(learning_rate=lr)\n",
    "#     model.compile(optimizer= adam, loss=tf.keras.losses.sparse_categorical_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "#     print(\"FITTING\")\n",
    "#     history = model.fit(np.array(x_train), np.array(y_train), epochs=10, validation_data=(np.array(x_test), np.array(y_test)))\n",
    "#     plt.plot(history.history['accuracy'], label='accuracy')\n",
    "#     plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "#     plt.xlabel('Epoch')\n",
    "#     plt.ylabel('Accuracy')\n",
    "#     plt.ylim([0.5, 1])\n",
    "#     plt.legend(loc='lower right')\n",
    "#     plt.title(\"Learning Rate: \" + str(lr))\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# LR = .0001 achieves the highest validation accuracy\n",
    "# Increase number of epochs to see if more epochs further increases val error\n",
    "LR = .0001\n",
    "model = VGG16(weights=None, include_top=True, input_shape= (50, 50,3), classes=2, classifier_activation='softmax')\n",
    "adam = Adam(learning_rate=LR)\n",
    "model.compile(optimizer= adam, loss=tf.keras.losses.sparse_categorical_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "print(\"FITTING\")\n",
    "history = model.fit(train_iterator, epochs=15, validation_data=val_iterator)\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.5, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.title(\"Learning Rate: \" + str(LR))\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LR = .0001 achieves the highest validation accuracy\n",
    "# Increase number of epochs to see if more epochs further increases val error\n",
    "model = VGG16(weights=None, include_top=True, input_shape= (50, 50,3), classes=2, classifier_activation='softmax')\n",
    "adam = Adam(learning_rate=.0001)\n",
    "model.compile(optimizer= adam, loss=tf.keras.losses.sparse_categorical_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "print(\"FITTING\")\n",
    "history = model.fit(np.array(x_train), np.array(y_train), epochs=15, validation_data=(np.array(x_test), np.array(y_test)))\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.5, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.title(\"Learning Rate: \" + str(lr))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_data(paths, start, stop, label):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for path in paths[start:stop]:\n",
    "        image = load_img(path)\n",
    "        image = image.resize([50, 50])\n",
    "        imgArray = tf.keras.utils.img_to_array(image)\n",
    "        images.append(imgArray)\n",
    "        labels.append(label)\n",
    "        \n",
    "    return [tf.keras.applications.vgg16.preprocess_input(np.array(images)), np.array(labels)]\n",
    "        \n",
    "cancer_test = get_test_data(cancerousPaths, 20000, 30000, 1)\n",
    "benign_test = get_test_data(nonCancerPaths, 20000, 30000, 0)\n",
    "model.evaluate(cancer_test[0], cancer_test[1])\n",
    "model.evaluate(benign_test[0], benign_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(allImages, allLabels, test_size=.20, stratify= allLabels, random_state = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nonCancerPaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cancerousPaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
